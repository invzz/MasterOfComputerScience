# Why partitioning is relevant

---

Splitting a big dabase inoto smaller datasets called partitionjss so that different partitions ca be assigned to different  nodes (*sharding*

**intra operation parallelism:**

- different instances of the same operation are processed in parallel, by executing them in parallel over different nodes
- common referred as *data parallelism*
- scalable approach
- the basis of cluster computing

**Assumptions:**

- shared nothing arch
- scalable distributed data system
- data locality prociple

- Data as a set of n records R with attributes (K,A,B,C)
- Load: set of frequent r/w accesses with respect to attribute K
- K can be chosen as partion key

---

## How to partition

- Each dataset is devided into p partitions where p depends on dataset size and access frequently
- Favour **balanced partitioning**
  - skewed partitions non scalable (the load is not evenly)
- Avoid **hot spots** partitions with disproportionately high load (large partition, higher number of requests)


---

## kinds of query

- **batch query**
  - read all data items
  - typical of analytical process
- **piont query**
  - selection of single record
  - typical of transactional processing
- **multipoint / range query**
  - selection of a range of records satysfing a given condition 
  - typical of transactional processing

---

## Block based partitioning

- Hadoop arch
- Arbitraly partition data such that the same amount of data n/p is places at each node
- use round robin approach or place the first n/p into the second node and so on
- no hotspots


**Pro / Cons :**

- Good for scanning full relation
- Not good for point or range queries

